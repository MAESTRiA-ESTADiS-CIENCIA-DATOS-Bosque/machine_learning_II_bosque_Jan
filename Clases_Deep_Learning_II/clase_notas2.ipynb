{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization NN in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 648x648 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_OptionsDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>\n"
     ]
    }
   ],
   "source": [
    "(ds_train_mnist, ds_test_mnist), ds_info_mnist = tfds.load(\n",
    "    name = 'mnist',\n",
    "    split=['train[:30%]', 'test[:30%]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True)\n",
    "fig = tfds.show_examples(ds_train_mnist, ds_info_mnist)\n",
    "print(ds_train_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 28, 28, 1) (32, 10)\n"
     ]
    }
   ],
   "source": [
    "trainprocess = tf.keras.Sequential([                \n",
    "        layers.Rescaling(scale=1.0 / 255.)\n",
    "    ],name='preprocess')\n",
    "\n",
    "def one_hot(dx,dy):\n",
    "    return trainprocess(dx), tf.one_hot(\n",
    "    dy, 10)\n",
    "Batch=32\n",
    "def data_load_sequential(data_ds,shuffle_train=True ,batch_=Batch):\n",
    "    data_ds=data_ds.map(one_hot)\n",
    "    data_ds = data_ds.cache()\n",
    "    if shuffle_train:\n",
    "        data_ds = data_ds.shuffle(len(data_ds))\n",
    "    data_ds = data_ds.batch(batch_)\n",
    "    data_ds = data_ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return data_ds\n",
    "\n",
    "data_train_mnist = data_load_sequential(ds_train_mnist)\n",
    "data_test_mnist = data_load_sequential(ds_test_mnist,shuffle_train=False)\n",
    "for ds,lb in data_train_mnist.take(1):\n",
    "    print(ds.shape,lb.shape)\n",
    "shaped_mnist=ds[0].numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5408)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                346176    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 347,146\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=shaped_mnist))\n",
    "model.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2,monitor=\"val_loss\", mode=\"min\"),\n",
    "    tf.keras.callbacks.ModelCheckpoint(filepath='carpeta_resultados_/model.h5',monitor='val_loss',\\\n",
    "                                       save_best_only=True ,mode='min' ),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='carpeta_resultados/logs', histogram_freq=1),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "563/563 [==============================] - 10s 15ms/step - loss: 0.3195 - accuracy: 0.9061 - val_loss: 0.1261 - val_accuracy: 0.9597\n",
      "Epoch 2/5\n",
      "563/563 [==============================] - 8s 14ms/step - loss: 0.1048 - accuracy: 0.9691 - val_loss: 0.0778 - val_accuracy: 0.9750\n",
      "Epoch 3/5\n",
      "563/563 [==============================] - 8s 15ms/step - loss: 0.0682 - accuracy: 0.9797 - val_loss: 0.0836 - val_accuracy: 0.9720\n",
      "Epoch 4/5\n",
      "563/563 [==============================] - 10s 17ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.0936 - val_accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "Epochs=5\n",
    "history=model.fit(data_train_mnist,validation_data=data_test_mnist, epochs=Epochs,verbose=1, callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 6ms/step - loss: 0.0936 - accuracy: 0.9680\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09356950223445892, 0.9679999947547913]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(data_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.006011962890625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados_/model.h5'))/float(2**20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "step =np.ceil(len(data_train_mnist)/Batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunning_params = {\n",
    "   'prunning_schedule':tfmot.sparsity.keras.PolynomialDecay(\n",
    "    initial_sparsity=0.0,\n",
    "    final_sparsity= 0.5,\n",
    "    begin_step= step*Batch,\n",
    "    end_step =step*Batch*5\n",
    "   )}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javier/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/javier/.local/lib/python3.8/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "model_for_prunning = tfmot.sparsity.keras.prune_low_magnitude(model, **prunning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_conv2d   (None, 26, 26, 32)       610       \n",
      " (PruneLowMagnitude)                                             \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 32)       1         \n",
      " ling2d (PruneLowMagnitude)                                      \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 5408)             1         \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      " prune_low_magnitude_dense (  (None, 64)               692290    \n",
      " PruneLowMagnitude)                                              \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_1  (None, 10)               1292      \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 694,194\n",
      "Trainable params: 347,146\n",
      "Non-trainable params: 347,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_for_prunning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_for_prunning.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_prunning=[\n",
    "    tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "    tfmot.sparsity.keras.PruningSummaries(log_dir='carpeta_resultados/log_prunning/')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  6/563 [..............................] - ETA: 6s - loss: 0.0293 - accuracy: 0.9948   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.0123s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0107s vs `on_train_batch_end` time: 0.0123s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "563/563 [==============================] - 12s 16ms/step - loss: 0.0387 - accuracy: 0.9887 - val_loss: 0.0656 - val_accuracy: 0.9780\n",
      "Epoch 2/5\n",
      "563/563 [==============================] - 10s 17ms/step - loss: 0.0227 - accuracy: 0.9943 - val_loss: 0.0654 - val_accuracy: 0.9777\n",
      "Epoch 3/5\n",
      "563/563 [==============================] - 9s 15ms/step - loss: 0.0153 - accuracy: 0.9963 - val_loss: 0.0661 - val_accuracy: 0.9767\n",
      "Epoch 4/5\n",
      "563/563 [==============================] - 9s 16ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0752 - val_accuracy: 0.9747\n",
      "Epoch 5/5\n",
      "563/563 [==============================] - 9s 16ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0667 - val_accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febe4719bb0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_prunning.fit(data_train_mnist,epochs=5, validation_data=data_test_mnist,callbacks=callback_prunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 7ms/step - loss: 0.0667 - accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06672260910272598, 0.9793333411216736]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_for_prunning.evaluate(data_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prunning_export = tfmot.sparsity.keras.strip_pruning(model_for_prunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model_prunning_export.save('carpeta_resultados_/model_prunning.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3417129516601562"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados_/model_prunning.h5'))/float(2**20) ##3X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 1s 4ms/step - loss: 0.0667 - accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06672260910272598, 0.9793333411216736]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_prunning_export.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n",
    "model_prunning_export.evaluate(data_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter =tf.lite.TFLiteConverter.from_keras_model(model_prunning_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_2mofggt/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmp_2mofggt/assets\n"
     ]
    }
   ],
   "source": [
    "model_prunning_export_tflite =converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carpeta_resultados_/model_prunning_tf_lite.tflite', 'wb') as f:\n",
    "    f.write(model_prunning_export_tflite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.32684326171875"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados_/model_prunning_tf_lite.tflite'))/float(2**20) ##3X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "converterq =tf.lite.TFLiteConverter.from_keras_model(model_prunning_export)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "converterq.optimizations =[tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbb79vzi1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpbb79vzi1/assets\n"
     ]
    }
   ],
   "source": [
    "quantization_model =converterq.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carpeta_resultados_/model_prunning_quant_tf_lite.tflite', 'wb') as f:\n",
    "    f.write(quantization_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33667755126953125"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados_/model_prunning_quant_tf_lite.tflite'))/float(2**20) ##10X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=quantization_model)\n",
    "interpreter.resize_tensor_input(0, [Batch,28,28,1])\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "output_index = interpreter.get_output_details()[0][\"index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for i, (img_test, label_test) in enumerate(data_test_mnist.take(93)):\n",
    "    interpreter.set_tensor(input_index,img_test)\n",
    "    interpreter.invoke()\n",
    "    output= interpreter.get_tensor(output_index)\n",
    "    target = np.argmax(label_test,axis=1)\n",
    "    prediction = np.argmax(output,axis=1)\n",
    "    acc= np.mean(target== prediction)\n",
    "    predict.append(acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.979502688172043\n"
     ]
    }
   ],
   "source": [
    "accuracy=np.mean(predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w1 = w0 -lr*grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_weights= tfmot.clustering.keras.cluster_weights\n",
    "centroid = tfmot.clustering.keras.CentroidInitialization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_params={\n",
    "    'number_of_clusters': 14,\n",
    "    'cluster_centroids_init': centroid.LINEAR\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model =cluster_weights(model,**cluster_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_model.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " cluster_conv2d (ClusterWeig  (None, 26, 26, 32)       622       \n",
      " hts)                                                            \n",
      "                                                                 \n",
      " cluster_max_pooling2d (Clus  (None, 13, 13, 32)       0         \n",
      " terWeights)                                                     \n",
      "                                                                 \n",
      " cluster_flatten (ClusterWei  (None, 5408)             0         \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      " cluster_dense (ClusterWeigh  (None, 64)               692302    \n",
      " ts)                                                             \n",
      "                                                                 \n",
      " cluster_dense_1 (ClusterWei  (None, 10)               1304      \n",
      " ghts)                                                           \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 694,228\n",
      "Trainable params: 347,188\n",
      "Non-trainable params: 347,040\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cluster_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "563/563 [==============================] - 23s 38ms/step - loss: 0.0131 - accuracy: 0.9971 - val_loss: 0.0796 - val_accuracy: 0.9760\n",
      "Epoch 2/2\n",
      "563/563 [==============================] - 21s 37ms/step - loss: 0.0070 - accuracy: 0.9985 - val_loss: 0.0964 - val_accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febe42edcd0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model.fit(data_train_mnist, validation_data=data_test_mnist,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 2s 22ms/step - loss: 0.0964 - accuracy: 0.9740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09643499553203583, 0.9739999771118164]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_model.evaluate(data_test_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_clustering = tfmot.clustering.keras.strip_clustering(cluster_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "final_model_clustering.save('carpeta_resultados/model_clustering.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3387603759765625"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados/model_clustering.h5'))/float(2**20) ##10X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter =tf.lite.TFLiteConverter.from_keras_model(final_model_clustering)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqrmt9k5v/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqrmt9k5v/assets\n"
     ]
    }
   ],
   "source": [
    "tfmodel_clustering =converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('carpeta_resultados/model_clustering_quant.tflite', 'wb') as f:\n",
    "    f.write(tfmodel_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33667755126953125"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(os.path.getsize('carpeta_resultados/model_clustering_quant.tflite'))/float(2**20) ##10X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(model_content=tfmodel_clustering)\n",
    "interpreter.resize_tensor_input(0, [Batch,28,28,1])\n",
    "interpreter.allocate_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict=[]\n",
    "for i, (img_test, label_test) in enumerate(data_test_mnist.take(93)):\n",
    "    interpreter.set_tensor(input_index,img_test)\n",
    "    interpreter.invoke()\n",
    "    output= interpreter.get_tensor(output_index)\n",
    "    target = np.argmax(label_test,axis=1)\n",
    "    prediction = np.argmax(output,axis=1)\n",
    "    acc= np.mean(target== prediction)\n",
    "    predict.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9741263440860215\n"
     ]
    }
   ],
   "source": [
    "accuracy=np.mean(predict)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Destillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5408)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                173088    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                330       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 173,738\n",
      "Trainable params: 173,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_teacher = tf.keras.Sequential()\n",
    "model_teacher.add(tf.keras.Input(shape=shaped_mnist))\n",
    "model_teacher.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model_teacher.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model_teacher.add(layers.Flatten())\n",
    "model_teacher.add(layers.Dense(32, activation='relu'))\n",
    "model_teacher.add(layers.Dense(10))\n",
    "model_teacher.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_teacher.compile(loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "563/563 [==============================] - 8s 13ms/step - loss: 0.3716 - accuracy: 0.8881 - val_loss: 0.1502 - val_accuracy: 0.9523\n",
      "Epoch 2/6\n",
      "563/563 [==============================] - 7s 13ms/step - loss: 0.1231 - accuracy: 0.9640 - val_loss: 0.1056 - val_accuracy: 0.9690\n",
      "Epoch 3/6\n",
      "563/563 [==============================] - 6s 11ms/step - loss: 0.0789 - accuracy: 0.9790 - val_loss: 0.0886 - val_accuracy: 0.9717\n",
      "Epoch 4/6\n",
      "563/563 [==============================] - 8s 15ms/step - loss: 0.0590 - accuracy: 0.9824 - val_loss: 0.0773 - val_accuracy: 0.9757\n",
      "Epoch 5/6\n",
      "563/563 [==============================] - 9s 16ms/step - loss: 0.0458 - accuracy: 0.9870 - val_loss: 0.0694 - val_accuracy: 0.9757\n",
      "Epoch 6/6\n",
      "563/563 [==============================] - 10s 18ms/step - loss: 0.0344 - accuracy: 0.9901 - val_loss: 0.0695 - val_accuracy: 0.9753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7febb06a4b80>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Epochs=6\n",
    "model_teacher.fit(data_train_mnist, validation_data=data_test_mnist, epochs=Epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 13, 13, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2704)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 8)                 21640     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                90        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,890\n",
      "Trainable params: 21,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_student = tf.keras.Sequential()\n",
    "model_student.add(tf.keras.Input(shape=shaped_mnist))\n",
    "model_student.add(layers.Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
    "model_student.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model_student.add(layers.Flatten())\n",
    "model_student.add(layers.Dense(8, activation='relu'))\n",
    "model_student.add(layers.Dense(10))\n",
    "model_student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc train:  tf.Tensor(0.9459444, shape=(), dtype=float32)\n",
      "acc val:  tf.Tensor(0.948, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-0ce3c5a7c8cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloss_student\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdestillation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_student\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_student\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mtrain_metric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_student\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1110\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1113\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_DivNoNanGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m   1482\u001b[0m       array_ops.reshape(\n\u001b[1;32m   1483\u001b[0m           math_ops.reduce_sum(\n\u001b[0;32m-> 1484\u001b[0;31m               \u001b[0mgrad\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_no_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_no_nan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=invalid-unary-operand-type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m               ry),\n\u001b[1;32m   1486\u001b[0m           sy))\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mneg\u001b[0;34m(x, name)\u001b[0m\n\u001b[1;32m   6748\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6749\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6750\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   6751\u001b[0m         _ctx, \"Neg\", name, x)\n\u001b[1;32m   6752\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "temp= tf.constant(3.)\n",
    "alpha=tf.constant(0.5)\n",
    "optimizer =tf.keras.optimizers.Adam()\n",
    "loss_st = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "destillation_loss =tf.keras.losses.KLDivergence()\n",
    "train_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "val_metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "\n",
    "for epochs in range(Epochs):\n",
    "    for x,y in data_train_mnist:\n",
    "        predict_teacher = model_teacher.predict(x,verbose=0)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predict_student= model_student(x)\n",
    "            loss_student = loss_st(y,predict_student)\n",
    "            destillation =destillation_loss(\n",
    "                tf.nn.softmax(predict_teacher/temp,axis=1),\n",
    "                tf.nn.softmax(predict_student/temp,axis=1))*temp**2\n",
    "\n",
    "            loss = alpha*loss_student + (1.-alpha)*destillation\n",
    "\n",
    "        grads = tape.gradient(loss, model_student.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(grads, model_student.trainable_weights))\n",
    "        train_metric.update_state(y, predict_student)\n",
    "    tracc=train_metric.result()\n",
    "    print(\"acc train: \",tracc )\n",
    "    train_acc =train_metric.reset_states()\n",
    "\n",
    "    for x_val, y_val in data_test_mnist:\n",
    "        predict_val =model_student(x_val)\n",
    "        val_metric.update_state(y_val,predict_val )\n",
    "    valcc=val_metric.result()\n",
    "    print(\"acc val: \",valcc)\n",
    "    val_metric.reset_states()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "es_tf27",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c6b0be8ac2a13bbd3b02aa547ccc5a3e5e0876834d4e8b778eb84ebe3cdaca80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
